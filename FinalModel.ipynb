{"cells":[{"cell_type":"markdown","metadata":{"id":"Cnl2e2EEYyFf"},"source":["\n","\n","# AN2DL Homework 1 - Final Model Notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24467,"status":"ok","timestamp":1732460076329,"user":{"displayName":"Rosario Napoli","userId":"16200523913878401815"},"user_tz":-60},"id":"QCN7AGixqXMb","outputId":"2bd9ab83-6abe-41f3-c8b4-76cc5f7b7814"},"outputs":[],"source":["COLAB = False\n","\n","if COLAB:\n","  from google.colab import drive\n","  !pip install keras_cv -qq\n","  drive.mount('/gdrive')\n","  %cd /gdrive/My Drive/ANN_new\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9385,"status":"ok","timestamp":1732460085704,"user":{"displayName":"Rosario Napoli","userId":"16200523913878401815"},"user_tz":-60},"id":"hLHX8YwGCgaI"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-24 23:17:45.694652: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1732486665.778315   90305 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1732486665.803126   90305 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-24 23:17:46.075591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","/home/franco/Dropbox/AA_Fra_Rosnati/B_Education/AA_University/AA_PoliMi/AA_Ing/01_Magistrale/HPC_engineering/3_sem_HPC/ANN/Challenge1/ANN-blood-cells/.kerasVenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","import keras_cv as kcv\n","from tensorflow.keras.applications import EfficientNetB2\n","from tensorflow.keras.applications.efficientnet import preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D, Dropout, BatchNormalization, Resizing, Rescaling, LeakyReLU, ELU\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","SEED = 42\n","\n","# Choose a name for the model\n","model_string = 'finalModel'\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8043,"status":"ok","timestamp":1732460093737,"user":{"displayName":"Rosario Napoli","userId":"16200523913878401815"},"user_tz":-60},"id":"38oY971YM5-z","outputId":"63d9ea47-8e0b-442d-d992-324c4de6fa13"},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape: (11951, 96, 96, 3)\n","y shape: (11951,)\n"]}],"source":["# Load dataset\n","data = np.load('data/training_set_clean.npz')\n","X = data['images']\n","y = data['labels']\n","\n","print(f'X shape: {X.shape}')\n","print(f'y shape: {y.shape}')"]},{"cell_type":"markdown","metadata":{"id":"fYlH5fObZD2I"},"source":["## Augmentations"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1732460094037,"user":{"displayName":"Rosario Napoli","userId":"16200523913878401815"},"user_tz":-60},"id":"FNm27z_40EmX"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-24 23:18:17.581093: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"]}],"source":["# -------------------- #\n","# Keras augmentations\n","# -------------------- #\n","\n","augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip('horizontal'),\n","    tf.keras.layers.RandomRotation(0.7),\n","    tf.keras.layers.RandomBrightness(0.2),\n","    tf.keras.layers.RandomTranslation(height_factor=0.15, width_factor=0.15),\n","    tf.keras.layers.RandomZoom(0.3)\n","])\n","\n","\n","# -------------------- #\n","# KerasCV\n","# -------------------- #\n","\n","rand_augment = kcv.layers.RandAugment(\n","    value_range=(0, 255),\n","    augmentations_per_image=4,\n","    magnitude=0.6,\n","    magnitude_stddev=0.2,\n","    rate=0.8\n",")\n","\n","random_cutout = kcv.layers.RandomCutout(\n","    height_factor=0.2,\n","    width_factor=0.2,\n","    fill_mode=\"constant\",\n","    fill_value=0.0,\n","    seed=2378\n",")\n","\n","def augment(images, labels, batch_index):\n","    # It is possbile to have different augments in different batches,\n","    # use an if statement based on 'batch_index'\n","\n","    # Ensure images are float32\n","    images = tf.cast(images, tf.float32)\n","\n","    images = rand_augment(images)\n","    images = random_cutout(images)\n","\n","    return images, labels\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LSZBAjLCVvVd"},"source":["![chosen_augs](./img/ourgmentations.png)"]},{"cell_type":"markdown","metadata":{"id":"QJPXs6bKVvCE"},"source":["## Transfer Learning"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1830,"status":"ok","timestamp":1732460095855,"user":{"displayName":"Rosario Napoli","userId":"16200523913878401815"},"user_tz":-60},"id":"idZ0gDMVaBpC"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-24 23:18:31.648557: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1057259520 exceeds 10% of free system memory.\n"]}],"source":["# Normalize and preprocess images\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n","X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n","\n","# One-hot encode labels\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes=8).astype(np.float32)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes=8).astype(np.float32)\n","\n","# autotune\n","AUTOTUNE = tf.data.AUTOTUNE"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6981,"status":"ok","timestamp":1732460102830,"user":{"displayName":"Rosario Napoli","userId":"16200523913878401815"},"user_tz":-60},"id":"k1XQ9nhW0fyv","outputId":"4944bf52-2ec4-4541-8879-69777884b919"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n","\u001b[1m31790344/31790344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ resizing (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Resizing</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ efficientnetb2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,768,569</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">721,408</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ resizing (\u001b[38;5;33mResizing\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m260\u001b[0m, \u001b[38;5;34m260\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m260\u001b[0m, \u001b[38;5;34m260\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ efficientnetb2 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1408\u001b[0m)     │     \u001b[38;5;34m7,768,569\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │         \u001b[38;5;34m5,632\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m721,408\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,663,937</span> (33.05 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,663,937\u001b[0m (33.05 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">891,016</span> (3.40 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m891,016\u001b[0m (3.40 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,772,921</span> (29.65 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,772,921\u001b[0m (29.65 MB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["\n","# ---------------- #\n","# Preparation\n","# ---------------- #\n","\n","def prepare_dataset(images, labels, is_training=True, batch_size=32):\n","\n","    # Create the base dataset\n","    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n","\n","    if is_training:\n","        dataset = dataset.shuffle(buffer_size=1024)\n","\n","    # Apply EfficientNet preprocessing\n","    def preprocess(images, labels):\n","        images = preprocess_input(images)\n","        return images, labels\n","\n","    dataset = dataset.map(preprocess, num_parallel_calls=AUTOTUNE)\n","\n","    # Batch before augmentation\n","    dataset = dataset.batch(batch_size)\n","\n","    if is_training:\n","\n","        # It is possbile to have different augments in different batches\n","        def augment_with_index(batch_index, data):\n","            images, labels = data\n","            return augment(images, labels, batch_index)\n","\n","        dataset = dataset.enumerate().map(\n","            augment_with_index, num_parallel_calls=AUTOTUNE\n","        )\n","\n","    return dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","\n","# Prepare datasets\n","train_dataset = prepare_dataset(X_train, y_train, is_training=True, batch_size=32)\n","val_dataset = prepare_dataset(X_test, y_test, is_training=False, batch_size=32)\n","\n","\n","\n","# ---------------- #\n","# Build model\n","# ---------------- #\n","\n","# Create the model\n","def create_model(input_shape=(96, 96, 3), num_classes=8, augmentation=None):\n","    input_layer = Input(shape=input_shape)\n","\n","    # Resizing layer for prediction to resize images to 224x224\n","    x = Resizing(260, 260)(input_layer)\n","\n","    # Base model\n","    base_model = EfficientNetB2(weights='imagenet', include_top=False)\n","    base_model.trainable = False\n","\n","    # Model architecture\n","    # with Activation Function LeakyReLU\n","    x = augmentation(x)\n","    x = base_model(x, training=False)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dropout(0.2)(x)\n","    x = BatchNormalization()(x)\n","    x = Dense(512, activation=None)(x)\n","    x = LeakyReLU(negative_slope=0.05)(x)\n","    x = Dropout(0.1)(x)\n","    x = BatchNormalization()(x)\n","    x = Dense(256, activation=None)(x)\n","    x = LeakyReLU(negative_slope=0.05)(x)\n","    x = Dropout(0.1)(x)\n","    x = BatchNormalization()(x)\n","    x = Dense(128, activation=None)(x)\n","    x = LeakyReLU(negative_slope=0.05)(x)\n","    output_layer = Dense(num_classes, activation='softmax')(x)\n","\n","    return Model(inputs=input_layer, outputs=output_layer)\n","\n","\n","# ---------------- #\n","# Create & Compile\n","# ---------------- #\n","\n","model = create_model(augmentation=augmentation)\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=0.001,\n","    decay_steps=1000,\n","    decay_rate=0.95\n",")\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n","model.compile(\n","    optimizer=optimizer,\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","\n","# ---------------- #\n","# Other settings\n","# ---------------- #\n","\n","# Callbacks\n","callbacks = [\n","    EarlyStopping(\n","        monitor='val_accuracy',\n","        patience=15,\n","        restore_best_weights=True\n","    ),\n","    ModelCheckpoint(\n","        'models/' + model_string + '.keras',\n","        monitor='val_accuracy',\n","        save_best_only=True,\n","        mode='max'\n","    )\n","]\n","\n","# Compute class weights\n","class_weights = compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(np.argmax(y_train, axis=1)),\n","    y=np.argmax(y_train, axis=1)\n",")\n","class_weights = dict(enumerate(class_weights))\n","\n","model.summary()\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2913602,"status":"ok","timestamp":1732463016424,"user":{"displayName":"Rosario Napoli","userId":"16200523913878401815"},"user_tz":-60},"id":"zk409fMtYuWz","outputId":"0f051975-0e4d-4382-f2c1-b02374272455"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 136ms/step - accuracy: 0.3673 - loss: 1.7950 - val_accuracy: 0.6642 - val_loss: 0.8978\n","Epoch 2/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 128ms/step - accuracy: 0.5165 - loss: 1.3558 - val_accuracy: 0.7900 - val_loss: 0.6592\n","Epoch 3/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.5408 - loss: 1.2956 - val_accuracy: 0.8114 - val_loss: 0.5425\n","Epoch 4/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.5403 - loss: 1.2872 - val_accuracy: 0.8210 - val_loss: 0.5359\n","Epoch 5/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.5589 - loss: 1.2259 - val_accuracy: 0.7465 - val_loss: 0.7003\n","Epoch 6/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.5758 - loss: 1.1992 - val_accuracy: 0.8009 - val_loss: 0.5939\n","Epoch 7/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.5803 - loss: 1.1706 - val_accuracy: 0.8197 - val_loss: 0.5493\n","Epoch 8/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.5736 - loss: 1.1857 - val_accuracy: 0.8130 - val_loss: 0.5643\n","Epoch 9/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.5919 - loss: 1.1494 - val_accuracy: 0.8565 - val_loss: 0.4649\n","Epoch 10/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.5874 - loss: 1.1546 - val_accuracy: 0.7980 - val_loss: 0.5752\n","Epoch 11/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.5950 - loss: 1.1214 - val_accuracy: 0.7900 - val_loss: 0.6198\n","Epoch 12/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 127ms/step - accuracy: 0.5990 - loss: 1.1153 - val_accuracy: 0.8114 - val_loss: 0.5376\n","Epoch 13/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.5986 - loss: 1.1130 - val_accuracy: 0.8302 - val_loss: 0.4975\n","Epoch 14/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.6068 - loss: 1.1158 - val_accuracy: 0.8653 - val_loss: 0.4222\n","Epoch 15/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6156 - loss: 1.0734 - val_accuracy: 0.8515 - val_loss: 0.4621\n","Epoch 16/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6193 - loss: 1.0874 - val_accuracy: 0.8528 - val_loss: 0.4416\n","Epoch 17/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.6099 - loss: 1.0884 - val_accuracy: 0.8703 - val_loss: 0.4062\n","Epoch 18/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.5987 - loss: 1.1107 - val_accuracy: 0.8695 - val_loss: 0.4107\n","Epoch 19/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.6136 - loss: 1.0807 - val_accuracy: 0.8708 - val_loss: 0.4231\n","Epoch 20/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.6157 - loss: 1.0977 - val_accuracy: 0.8875 - val_loss: 0.3526\n","Epoch 21/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6035 - loss: 1.0784 - val_accuracy: 0.8683 - val_loss: 0.4202\n","Epoch 22/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6151 - loss: 1.0609 - val_accuracy: 0.8699 - val_loss: 0.4209\n","Epoch 23/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6155 - loss: 1.0721 - val_accuracy: 0.8607 - val_loss: 0.4105\n","Epoch 24/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6202 - loss: 1.0512 - val_accuracy: 0.8603 - val_loss: 0.4232\n","Epoch 25/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.6293 - loss: 1.0265 - val_accuracy: 0.8904 - val_loss: 0.3683\n","Epoch 26/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6192 - loss: 1.0697 - val_accuracy: 0.8841 - val_loss: 0.3718\n","Epoch 27/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6134 - loss: 1.0592 - val_accuracy: 0.8745 - val_loss: 0.3849\n","Epoch 28/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.6155 - loss: 1.0607 - val_accuracy: 0.9034 - val_loss: 0.3272\n","Epoch 29/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6283 - loss: 1.0246 - val_accuracy: 0.8971 - val_loss: 0.3614\n","Epoch 30/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6337 - loss: 1.0370 - val_accuracy: 0.8800 - val_loss: 0.3918\n","Epoch 31/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6383 - loss: 1.0216 - val_accuracy: 0.8570 - val_loss: 0.4059\n","Epoch 32/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6297 - loss: 1.0411 - val_accuracy: 0.8913 - val_loss: 0.3680\n","Epoch 33/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6357 - loss: 1.0266 - val_accuracy: 0.8925 - val_loss: 0.3609\n","Epoch 34/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6354 - loss: 1.0103 - val_accuracy: 0.8841 - val_loss: 0.3628\n","Epoch 35/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 127ms/step - accuracy: 0.6367 - loss: 1.0198 - val_accuracy: 0.8699 - val_loss: 0.3910\n","Epoch 36/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6352 - loss: 1.0398 - val_accuracy: 0.8942 - val_loss: 0.3646\n","Epoch 37/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6551 - loss: 0.9904 - val_accuracy: 0.8971 - val_loss: 0.3301\n","Epoch 38/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.6379 - loss: 1.0108 - val_accuracy: 0.9059 - val_loss: 0.2961\n","Epoch 39/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6427 - loss: 0.9990 - val_accuracy: 0.8942 - val_loss: 0.3218\n","Epoch 40/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6393 - loss: 0.9824 - val_accuracy: 0.9021 - val_loss: 0.3214\n","Epoch 41/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6346 - loss: 1.0026 - val_accuracy: 0.8950 - val_loss: 0.3288\n","Epoch 42/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6422 - loss: 1.0175 - val_accuracy: 0.8992 - val_loss: 0.3241\n","Epoch 43/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 127ms/step - accuracy: 0.6409 - loss: 0.9940 - val_accuracy: 0.8963 - val_loss: 0.3332\n","Epoch 44/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6354 - loss: 1.0016 - val_accuracy: 0.8741 - val_loss: 0.3733\n","Epoch 45/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6441 - loss: 1.0055 - val_accuracy: 0.8954 - val_loss: 0.3420\n","Epoch 46/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6405 - loss: 0.9896 - val_accuracy: 0.8954 - val_loss: 0.3466\n","Epoch 47/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6523 - loss: 0.9920 - val_accuracy: 0.8854 - val_loss: 0.3496\n","Epoch 48/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6466 - loss: 0.9859 - val_accuracy: 0.9013 - val_loss: 0.3095\n","Epoch 49/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6504 - loss: 0.9943 - val_accuracy: 0.9055 - val_loss: 0.2931\n","Epoch 50/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6490 - loss: 0.9842 - val_accuracy: 0.9051 - val_loss: 0.3030\n","Epoch 51/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6527 - loss: 0.9737 - val_accuracy: 0.9038 - val_loss: 0.2935\n","Epoch 52/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6496 - loss: 0.9726 - val_accuracy: 0.8980 - val_loss: 0.2987\n","Epoch 53/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.6406 - loss: 0.9916 - val_accuracy: 0.9067 - val_loss: 0.2948\n","Epoch 54/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6534 - loss: 0.9706 - val_accuracy: 0.8996 - val_loss: 0.3040\n","Epoch 55/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6463 - loss: 0.9893 - val_accuracy: 0.8967 - val_loss: 0.3161\n","Epoch 56/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6589 - loss: 0.9464 - val_accuracy: 0.8946 - val_loss: 0.3226\n","Epoch 57/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.6572 - loss: 0.9543 - val_accuracy: 0.9118 - val_loss: 0.2880\n","Epoch 58/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 127ms/step - accuracy: 0.6636 - loss: 0.9364 - val_accuracy: 0.9038 - val_loss: 0.3116\n","Epoch 59/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6511 - loss: 0.9646 - val_accuracy: 0.9030 - val_loss: 0.3125\n","Epoch 60/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6505 - loss: 0.9692 - val_accuracy: 0.9005 - val_loss: 0.3097\n","Epoch 61/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6628 - loss: 0.9641 - val_accuracy: 0.9046 - val_loss: 0.3072\n","Epoch 62/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6557 - loss: 0.9801 - val_accuracy: 0.9092 - val_loss: 0.2959\n","Epoch 63/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6650 - loss: 0.9586 - val_accuracy: 0.9051 - val_loss: 0.2911\n","Epoch 64/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6623 - loss: 0.9612 - val_accuracy: 0.9067 - val_loss: 0.2882\n","Epoch 65/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6563 - loss: 0.9645 - val_accuracy: 0.9059 - val_loss: 0.2893\n","Epoch 66/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 127ms/step - accuracy: 0.6652 - loss: 0.9514 - val_accuracy: 0.9092 - val_loss: 0.2874\n","Epoch 67/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6671 - loss: 0.9424 - val_accuracy: 0.9034 - val_loss: 0.2943\n","Epoch 68/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6595 - loss: 0.9527 - val_accuracy: 0.9038 - val_loss: 0.2905\n","Epoch 69/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6704 - loss: 0.9331 - val_accuracy: 0.9009 - val_loss: 0.3043\n","Epoch 70/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6609 - loss: 0.9652 - val_accuracy: 0.9088 - val_loss: 0.2860\n","Epoch 71/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6568 - loss: 0.9437 - val_accuracy: 0.9113 - val_loss: 0.2744\n","Epoch 72/100\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 126ms/step - accuracy: 0.6660 - loss: 0.9371 - val_accuracy: 0.9088 - val_loss: 0.2772\n"]}],"source":["# ---------------- #\n","# Train model\n","# ---------------- #\n","\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=100,\n","    callbacks=callbacks,\n","    class_weight=class_weights\n",")"]},{"cell_type":"markdown","metadata":{"id":"TfuoHFEwZSlD"},"source":["## Fine-tuning"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2342,"status":"ok","timestamp":1732463018747,"user":{"displayName":"Rosario Napoli","userId":"16200523913878401815"},"user_tz":-60},"id":"YzfoN6Q8zCum","outputId":"41e4a331-0661-46ad-a05a-887932dd9c66"},"outputs":[{"name":"stdout","output_type":"stream","text":["Layer 0: input_layer_1, Type: InputLayer, Trainable: False\n","Layer 1: rescaling, Type: Rescaling, Trainable: False\n","Layer 2: normalization, Type: Normalization, Trainable: False\n","Layer 3: rescaling_1, Type: Rescaling, Trainable: False\n","Layer 4: stem_conv_pad, Type: ZeroPadding2D, Trainable: False\n","Layer 5: stem_conv, Type: Conv2D, Trainable: False\n","Layer 6: stem_bn, Type: BatchNormalization, Trainable: False\n","Layer 7: stem_activation, Type: Activation, Trainable: False\n","Layer 8: block1a_dwconv, Type: DepthwiseConv2D, Trainable: False\n","Layer 9: block1a_bn, Type: BatchNormalization, Trainable: False\n","Layer 10: block1a_activation, Type: Activation, Trainable: False\n","Layer 11: block1a_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 12: block1a_se_reshape, Type: Reshape, Trainable: False\n","Layer 13: block1a_se_reduce, Type: Conv2D, Trainable: False\n","Layer 14: block1a_se_expand, Type: Conv2D, Trainable: False\n","Layer 15: block1a_se_excite, Type: Multiply, Trainable: False\n","Layer 16: block1a_project_conv, Type: Conv2D, Trainable: False\n","Layer 17: block1a_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 18: block1b_dwconv, Type: DepthwiseConv2D, Trainable: False\n","Layer 19: block1b_bn, Type: BatchNormalization, Trainable: False\n","Layer 20: block1b_activation, Type: Activation, Trainable: False\n","Layer 21: block1b_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 22: block1b_se_reshape, Type: Reshape, Trainable: False\n","Layer 23: block1b_se_reduce, Type: Conv2D, Trainable: False\n","Layer 24: block1b_se_expand, Type: Conv2D, Trainable: False\n","Layer 25: block1b_se_excite, Type: Multiply, Trainable: False\n","Layer 26: block1b_project_conv, Type: Conv2D, Trainable: False\n","Layer 27: block1b_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 28: block1b_drop, Type: Dropout, Trainable: False\n","Layer 29: block1b_add, Type: Add, Trainable: False\n","Layer 30: block2a_expand_conv, Type: Conv2D, Trainable: False\n","Layer 31: block2a_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 32: block2a_expand_activation, Type: Activation, Trainable: False\n","Layer 33: block2a_dwconv_pad, Type: ZeroPadding2D, Trainable: False\n","Layer 34: block2a_dwconv, Type: DepthwiseConv2D, Trainable: False\n","Layer 35: block2a_bn, Type: BatchNormalization, Trainable: False\n","Layer 36: block2a_activation, Type: Activation, Trainable: False\n","Layer 37: block2a_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 38: block2a_se_reshape, Type: Reshape, Trainable: False\n","Layer 39: block2a_se_reduce, Type: Conv2D, Trainable: False\n","Layer 40: block2a_se_expand, Type: Conv2D, Trainable: False\n","Layer 41: block2a_se_excite, Type: Multiply, Trainable: False\n","Layer 42: block2a_project_conv, Type: Conv2D, Trainable: False\n","Layer 43: block2a_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 44: block2b_expand_conv, Type: Conv2D, Trainable: False\n","Layer 45: block2b_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 46: block2b_expand_activation, Type: Activation, Trainable: False\n","Layer 47: block2b_dwconv, Type: DepthwiseConv2D, Trainable: False\n","Layer 48: block2b_bn, Type: BatchNormalization, Trainable: False\n","Layer 49: block2b_activation, Type: Activation, Trainable: False\n","Layer 50: block2b_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 51: block2b_se_reshape, Type: Reshape, Trainable: False\n","Layer 52: block2b_se_reduce, Type: Conv2D, Trainable: False\n","Layer 53: block2b_se_expand, Type: Conv2D, Trainable: False\n","Layer 54: block2b_se_excite, Type: Multiply, Trainable: False\n","Layer 55: block2b_project_conv, Type: Conv2D, Trainable: False\n","Layer 56: block2b_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 57: block2b_drop, Type: Dropout, Trainable: False\n","Layer 58: block2b_add, Type: Add, Trainable: False\n","Layer 59: block2c_expand_conv, Type: Conv2D, Trainable: False\n","Layer 60: block2c_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 61: block2c_expand_activation, Type: Activation, Trainable: False\n","Layer 62: block2c_dwconv, Type: DepthwiseConv2D, Trainable: False\n","Layer 63: block2c_bn, Type: BatchNormalization, Trainable: False\n","Layer 64: block2c_activation, Type: Activation, Trainable: False\n","Layer 65: block2c_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 66: block2c_se_reshape, Type: Reshape, Trainable: False\n","Layer 67: block2c_se_reduce, Type: Conv2D, Trainable: False\n","Layer 68: block2c_se_expand, Type: Conv2D, Trainable: False\n","Layer 69: block2c_se_excite, Type: Multiply, Trainable: False\n","Layer 70: block2c_project_conv, Type: Conv2D, Trainable: False\n","Layer 71: block2c_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 72: block2c_drop, Type: Dropout, Trainable: False\n","Layer 73: block2c_add, Type: Add, Trainable: False\n","Layer 74: block3a_expand_conv, Type: Conv2D, Trainable: False\n","Layer 75: block3a_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 76: block3a_expand_activation, Type: Activation, Trainable: False\n","Layer 77: block3a_dwconv_pad, Type: ZeroPadding2D, Trainable: False\n","Layer 78: block3a_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 79: block3a_bn, Type: BatchNormalization, Trainable: False\n","Layer 80: block3a_activation, Type: Activation, Trainable: False\n","Layer 81: block3a_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 82: block3a_se_reshape, Type: Reshape, Trainable: False\n","Layer 83: block3a_se_reduce, Type: Conv2D, Trainable: True\n","Layer 84: block3a_se_expand, Type: Conv2D, Trainable: True\n","Layer 85: block3a_se_excite, Type: Multiply, Trainable: False\n","Layer 86: block3a_project_conv, Type: Conv2D, Trainable: True\n","Layer 87: block3a_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 88: block3b_expand_conv, Type: Conv2D, Trainable: True\n","Layer 89: block3b_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 90: block3b_expand_activation, Type: Activation, Trainable: False\n","Layer 91: block3b_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 92: block3b_bn, Type: BatchNormalization, Trainable: False\n","Layer 93: block3b_activation, Type: Activation, Trainable: False\n","Layer 94: block3b_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 95: block3b_se_reshape, Type: Reshape, Trainable: False\n","Layer 96: block3b_se_reduce, Type: Conv2D, Trainable: True\n","Layer 97: block3b_se_expand, Type: Conv2D, Trainable: True\n","Layer 98: block3b_se_excite, Type: Multiply, Trainable: False\n","Layer 99: block3b_project_conv, Type: Conv2D, Trainable: True\n","Layer 100: block3b_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 101: block3b_drop, Type: Dropout, Trainable: False\n","Layer 102: block3b_add, Type: Add, Trainable: False\n","Layer 103: block3c_expand_conv, Type: Conv2D, Trainable: True\n","Layer 104: block3c_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 105: block3c_expand_activation, Type: Activation, Trainable: False\n","Layer 106: block3c_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 107: block3c_bn, Type: BatchNormalization, Trainable: False\n","Layer 108: block3c_activation, Type: Activation, Trainable: False\n","Layer 109: block3c_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 110: block3c_se_reshape, Type: Reshape, Trainable: False\n","Layer 111: block3c_se_reduce, Type: Conv2D, Trainable: True\n","Layer 112: block3c_se_expand, Type: Conv2D, Trainable: True\n","Layer 113: block3c_se_excite, Type: Multiply, Trainable: False\n","Layer 114: block3c_project_conv, Type: Conv2D, Trainable: True\n","Layer 115: block3c_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 116: block3c_drop, Type: Dropout, Trainable: False\n","Layer 117: block3c_add, Type: Add, Trainable: False\n","Layer 118: block4a_expand_conv, Type: Conv2D, Trainable: True\n","Layer 119: block4a_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 120: block4a_expand_activation, Type: Activation, Trainable: False\n","Layer 121: block4a_dwconv_pad, Type: ZeroPadding2D, Trainable: False\n","Layer 122: block4a_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 123: block4a_bn, Type: BatchNormalization, Trainable: False\n","Layer 124: block4a_activation, Type: Activation, Trainable: False\n","Layer 125: block4a_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 126: block4a_se_reshape, Type: Reshape, Trainable: False\n","Layer 127: block4a_se_reduce, Type: Conv2D, Trainable: True\n","Layer 128: block4a_se_expand, Type: Conv2D, Trainable: True\n","Layer 129: block4a_se_excite, Type: Multiply, Trainable: False\n","Layer 130: block4a_project_conv, Type: Conv2D, Trainable: True\n","Layer 131: block4a_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 132: block4b_expand_conv, Type: Conv2D, Trainable: True\n","Layer 133: block4b_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 134: block4b_expand_activation, Type: Activation, Trainable: False\n","Layer 135: block4b_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 136: block4b_bn, Type: BatchNormalization, Trainable: False\n","Layer 137: block4b_activation, Type: Activation, Trainable: False\n","Layer 138: block4b_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 139: block4b_se_reshape, Type: Reshape, Trainable: False\n","Layer 140: block4b_se_reduce, Type: Conv2D, Trainable: True\n","Layer 141: block4b_se_expand, Type: Conv2D, Trainable: True\n","Layer 142: block4b_se_excite, Type: Multiply, Trainable: False\n","Layer 143: block4b_project_conv, Type: Conv2D, Trainable: True\n","Layer 144: block4b_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 145: block4b_drop, Type: Dropout, Trainable: False\n","Layer 146: block4b_add, Type: Add, Trainable: False\n","Layer 147: block4c_expand_conv, Type: Conv2D, Trainable: True\n","Layer 148: block4c_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 149: block4c_expand_activation, Type: Activation, Trainable: False\n","Layer 150: block4c_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 151: block4c_bn, Type: BatchNormalization, Trainable: False\n","Layer 152: block4c_activation, Type: Activation, Trainable: False\n","Layer 153: block4c_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 154: block4c_se_reshape, Type: Reshape, Trainable: False\n","Layer 155: block4c_se_reduce, Type: Conv2D, Trainable: True\n","Layer 156: block4c_se_expand, Type: Conv2D, Trainable: True\n","Layer 157: block4c_se_excite, Type: Multiply, Trainable: False\n","Layer 158: block4c_project_conv, Type: Conv2D, Trainable: True\n","Layer 159: block4c_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 160: block4c_drop, Type: Dropout, Trainable: False\n","Layer 161: block4c_add, Type: Add, Trainable: False\n","Layer 162: block4d_expand_conv, Type: Conv2D, Trainable: True\n","Layer 163: block4d_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 164: block4d_expand_activation, Type: Activation, Trainable: False\n","Layer 165: block4d_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 166: block4d_bn, Type: BatchNormalization, Trainable: False\n","Layer 167: block4d_activation, Type: Activation, Trainable: False\n","Layer 168: block4d_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 169: block4d_se_reshape, Type: Reshape, Trainable: False\n","Layer 170: block4d_se_reduce, Type: Conv2D, Trainable: True\n","Layer 171: block4d_se_expand, Type: Conv2D, Trainable: True\n","Layer 172: block4d_se_excite, Type: Multiply, Trainable: False\n","Layer 173: block4d_project_conv, Type: Conv2D, Trainable: True\n","Layer 174: block4d_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 175: block4d_drop, Type: Dropout, Trainable: False\n","Layer 176: block4d_add, Type: Add, Trainable: False\n","Layer 177: block5a_expand_conv, Type: Conv2D, Trainable: True\n","Layer 178: block5a_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 179: block5a_expand_activation, Type: Activation, Trainable: False\n","Layer 180: block5a_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 181: block5a_bn, Type: BatchNormalization, Trainable: False\n","Layer 182: block5a_activation, Type: Activation, Trainable: False\n","Layer 183: block5a_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 184: block5a_se_reshape, Type: Reshape, Trainable: False\n","Layer 185: block5a_se_reduce, Type: Conv2D, Trainable: True\n","Layer 186: block5a_se_expand, Type: Conv2D, Trainable: True\n","Layer 187: block5a_se_excite, Type: Multiply, Trainable: False\n","Layer 188: block5a_project_conv, Type: Conv2D, Trainable: True\n","Layer 189: block5a_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 190: block5b_expand_conv, Type: Conv2D, Trainable: True\n","Layer 191: block5b_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 192: block5b_expand_activation, Type: Activation, Trainable: False\n","Layer 193: block5b_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 194: block5b_bn, Type: BatchNormalization, Trainable: False\n","Layer 195: block5b_activation, Type: Activation, Trainable: False\n","Layer 196: block5b_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 197: block5b_se_reshape, Type: Reshape, Trainable: False\n","Layer 198: block5b_se_reduce, Type: Conv2D, Trainable: True\n","Layer 199: block5b_se_expand, Type: Conv2D, Trainable: True\n","Layer 200: block5b_se_excite, Type: Multiply, Trainable: False\n","Layer 201: block5b_project_conv, Type: Conv2D, Trainable: True\n","Layer 202: block5b_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 203: block5b_drop, Type: Dropout, Trainable: False\n","Layer 204: block5b_add, Type: Add, Trainable: False\n","Layer 205: block5c_expand_conv, Type: Conv2D, Trainable: True\n","Layer 206: block5c_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 207: block5c_expand_activation, Type: Activation, Trainable: False\n","Layer 208: block5c_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 209: block5c_bn, Type: BatchNormalization, Trainable: False\n","Layer 210: block5c_activation, Type: Activation, Trainable: False\n","Layer 211: block5c_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 212: block5c_se_reshape, Type: Reshape, Trainable: False\n","Layer 213: block5c_se_reduce, Type: Conv2D, Trainable: True\n","Layer 214: block5c_se_expand, Type: Conv2D, Trainable: True\n","Layer 215: block5c_se_excite, Type: Multiply, Trainable: False\n","Layer 216: block5c_project_conv, Type: Conv2D, Trainable: True\n","Layer 217: block5c_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 218: block5c_drop, Type: Dropout, Trainable: False\n","Layer 219: block5c_add, Type: Add, Trainable: False\n","Layer 220: block5d_expand_conv, Type: Conv2D, Trainable: True\n","Layer 221: block5d_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 222: block5d_expand_activation, Type: Activation, Trainable: False\n","Layer 223: block5d_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 224: block5d_bn, Type: BatchNormalization, Trainable: False\n","Layer 225: block5d_activation, Type: Activation, Trainable: False\n","Layer 226: block5d_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 227: block5d_se_reshape, Type: Reshape, Trainable: False\n","Layer 228: block5d_se_reduce, Type: Conv2D, Trainable: True\n","Layer 229: block5d_se_expand, Type: Conv2D, Trainable: True\n","Layer 230: block5d_se_excite, Type: Multiply, Trainable: False\n","Layer 231: block5d_project_conv, Type: Conv2D, Trainable: True\n","Layer 232: block5d_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 233: block5d_drop, Type: Dropout, Trainable: False\n","Layer 234: block5d_add, Type: Add, Trainable: False\n","Layer 235: block6a_expand_conv, Type: Conv2D, Trainable: True\n","Layer 236: block6a_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 237: block6a_expand_activation, Type: Activation, Trainable: False\n","Layer 238: block6a_dwconv_pad, Type: ZeroPadding2D, Trainable: False\n","Layer 239: block6a_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 240: block6a_bn, Type: BatchNormalization, Trainable: False\n","Layer 241: block6a_activation, Type: Activation, Trainable: False\n","Layer 242: block6a_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 243: block6a_se_reshape, Type: Reshape, Trainable: False\n","Layer 244: block6a_se_reduce, Type: Conv2D, Trainable: True\n","Layer 245: block6a_se_expand, Type: Conv2D, Trainable: True\n","Layer 246: block6a_se_excite, Type: Multiply, Trainable: False\n","Layer 247: block6a_project_conv, Type: Conv2D, Trainable: True\n","Layer 248: block6a_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 249: block6b_expand_conv, Type: Conv2D, Trainable: True\n","Layer 250: block6b_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 251: block6b_expand_activation, Type: Activation, Trainable: False\n","Layer 252: block6b_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 253: block6b_bn, Type: BatchNormalization, Trainable: False\n","Layer 254: block6b_activation, Type: Activation, Trainable: False\n","Layer 255: block6b_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 256: block6b_se_reshape, Type: Reshape, Trainable: False\n","Layer 257: block6b_se_reduce, Type: Conv2D, Trainable: True\n","Layer 258: block6b_se_expand, Type: Conv2D, Trainable: True\n","Layer 259: block6b_se_excite, Type: Multiply, Trainable: False\n","Layer 260: block6b_project_conv, Type: Conv2D, Trainable: True\n","Layer 261: block6b_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 262: block6b_drop, Type: Dropout, Trainable: False\n","Layer 263: block6b_add, Type: Add, Trainable: False\n","Layer 264: block6c_expand_conv, Type: Conv2D, Trainable: True\n","Layer 265: block6c_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 266: block6c_expand_activation, Type: Activation, Trainable: False\n","Layer 267: block6c_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 268: block6c_bn, Type: BatchNormalization, Trainable: False\n","Layer 269: block6c_activation, Type: Activation, Trainable: False\n","Layer 270: block6c_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 271: block6c_se_reshape, Type: Reshape, Trainable: False\n","Layer 272: block6c_se_reduce, Type: Conv2D, Trainable: True\n","Layer 273: block6c_se_expand, Type: Conv2D, Trainable: True\n","Layer 274: block6c_se_excite, Type: Multiply, Trainable: False\n","Layer 275: block6c_project_conv, Type: Conv2D, Trainable: True\n","Layer 276: block6c_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 277: block6c_drop, Type: Dropout, Trainable: False\n","Layer 278: block6c_add, Type: Add, Trainable: False\n","Layer 279: block6d_expand_conv, Type: Conv2D, Trainable: True\n","Layer 280: block6d_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 281: block6d_expand_activation, Type: Activation, Trainable: False\n","Layer 282: block6d_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 283: block6d_bn, Type: BatchNormalization, Trainable: False\n","Layer 284: block6d_activation, Type: Activation, Trainable: False\n","Layer 285: block6d_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 286: block6d_se_reshape, Type: Reshape, Trainable: False\n","Layer 287: block6d_se_reduce, Type: Conv2D, Trainable: True\n","Layer 288: block6d_se_expand, Type: Conv2D, Trainable: True\n","Layer 289: block6d_se_excite, Type: Multiply, Trainable: False\n","Layer 290: block6d_project_conv, Type: Conv2D, Trainable: True\n","Layer 291: block6d_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 292: block6d_drop, Type: Dropout, Trainable: False\n","Layer 293: block6d_add, Type: Add, Trainable: False\n","Layer 294: block6e_expand_conv, Type: Conv2D, Trainable: True\n","Layer 295: block6e_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 296: block6e_expand_activation, Type: Activation, Trainable: False\n","Layer 297: block6e_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 298: block6e_bn, Type: BatchNormalization, Trainable: False\n","Layer 299: block6e_activation, Type: Activation, Trainable: False\n","Layer 300: block6e_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 301: block6e_se_reshape, Type: Reshape, Trainable: False\n","Layer 302: block6e_se_reduce, Type: Conv2D, Trainable: True\n","Layer 303: block6e_se_expand, Type: Conv2D, Trainable: True\n","Layer 304: block6e_se_excite, Type: Multiply, Trainable: False\n","Layer 305: block6e_project_conv, Type: Conv2D, Trainable: True\n","Layer 306: block6e_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 307: block6e_drop, Type: Dropout, Trainable: False\n","Layer 308: block6e_add, Type: Add, Trainable: False\n","Layer 309: block7a_expand_conv, Type: Conv2D, Trainable: True\n","Layer 310: block7a_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 311: block7a_expand_activation, Type: Activation, Trainable: False\n","Layer 312: block7a_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 313: block7a_bn, Type: BatchNormalization, Trainable: False\n","Layer 314: block7a_activation, Type: Activation, Trainable: False\n","Layer 315: block7a_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 316: block7a_se_reshape, Type: Reshape, Trainable: False\n","Layer 317: block7a_se_reduce, Type: Conv2D, Trainable: True\n","Layer 318: block7a_se_expand, Type: Conv2D, Trainable: True\n","Layer 319: block7a_se_excite, Type: Multiply, Trainable: False\n","Layer 320: block7a_project_conv, Type: Conv2D, Trainable: True\n","Layer 321: block7a_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 322: block7b_expand_conv, Type: Conv2D, Trainable: True\n","Layer 323: block7b_expand_bn, Type: BatchNormalization, Trainable: False\n","Layer 324: block7b_expand_activation, Type: Activation, Trainable: False\n","Layer 325: block7b_dwconv, Type: DepthwiseConv2D, Trainable: True\n","Layer 326: block7b_bn, Type: BatchNormalization, Trainable: False\n","Layer 327: block7b_activation, Type: Activation, Trainable: False\n","Layer 328: block7b_se_squeeze, Type: GlobalAveragePooling2D, Trainable: False\n","Layer 329: block7b_se_reshape, Type: Reshape, Trainable: False\n","Layer 330: block7b_se_reduce, Type: Conv2D, Trainable: True\n","Layer 331: block7b_se_expand, Type: Conv2D, Trainable: True\n","Layer 332: block7b_se_excite, Type: Multiply, Trainable: False\n","Layer 333: block7b_project_conv, Type: Conv2D, Trainable: True\n","Layer 334: block7b_project_bn, Type: BatchNormalization, Trainable: False\n","Layer 335: block7b_drop, Type: Dropout, Trainable: False\n","Layer 336: block7b_add, Type: Add, Trainable: False\n","Layer 337: top_conv, Type: Conv2D, Trainable: True\n","Layer 338: top_bn, Type: BatchNormalization, Trainable: False\n","Layer 339: top_activation, Type: Activation, Trainable: False\n"]}],"source":["# Reload model\n","model = tf.keras.models.load_model('models/' + model_string + '.keras')\n","\n","\n","# ---------------- #\n","# Unfreeze\n","# ---------------- #\n","\n","N = 78 # Number of layers to freeze\n","\n","for i, layer in enumerate(model.get_layer('efficientnetb2').layers):\n","    layer.trainable = True\n","\n","for i, layer in enumerate(model.get_layer('efficientnetb2').layers):\n","    layer.trainable = False\n","\n","\n","for i, layer in enumerate(model.get_layer('efficientnetb2').layers):\n","    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n","        layer.trainable = True\n","\n","\n","# Set the first N layers as non-trainable\n","for i, layer in enumerate(model.get_layer('efficientnetb2').layers[:N]):\n","    layer.trainable = False\n","\n","# Print layer indices, names, and trainability status\n","for i, layer in enumerate(model.get_layer('efficientnetb2').layers):\n","    print(f\"Layer {i}: {layer.name}, Type: {type(layer).__name__}, Trainable: {layer.trainable}\")\n","\n","\n","\n","# -------------------- #\n","# fine-tune settings\n","# -------------------- #\n","\n","# Use a lower learning rate for fine-tuning\n","fine_tune_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=0.00001,  # Small learning rate for fine-tuning\n","    decay_steps=1000,\n","    decay_rate=0.95\n",")\n","fine_tune_optimizer = tf.keras.optimizers.Lion(\n","    learning_rate=fine_tune_lr_schedule\n",")\n","# fine_tune_optimizer = tf.keras.optimizers.Adam(learning_rate=fine_tune_lr_schedule)\n","model.compile(optimizer=fine_tune_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Additional callbacks\n","fine_tune_early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n","fine_tune_checkpoint = ModelCheckpoint('models/' + model_string + '_ft.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":980175,"status":"ok","timestamp":1732463998885,"user":{"displayName":"Rosario Napoli","userId":"16200523913878401815"},"user_tz":-60},"id":"Pb0MW7YGYqaw","outputId":"d4db0d97-b800-446b-ba40-452d2e53daf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 195ms/step - accuracy: 0.6917 - loss: 0.8666 - val_accuracy: 0.9448 - val_loss: 0.1567\n","Epoch 2/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.7895 - loss: 0.6421 - val_accuracy: 0.9636 - val_loss: 0.1069\n","Epoch 3/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.8092 - loss: 0.5492 - val_accuracy: 0.9757 - val_loss: 0.0730\n","Epoch 4/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 179ms/step - accuracy: 0.8247 - loss: 0.5000 - val_accuracy: 0.9749 - val_loss: 0.0836\n","Epoch 5/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.8411 - loss: 0.4501 - val_accuracy: 0.9812 - val_loss: 0.0607\n","Epoch 6/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 179ms/step - accuracy: 0.8486 - loss: 0.4430 - val_accuracy: 0.9766 - val_loss: 0.0756\n","Epoch 7/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.8621 - loss: 0.4123 - val_accuracy: 0.9833 - val_loss: 0.0505\n","Epoch 8/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 179ms/step - accuracy: 0.8654 - loss: 0.3944 - val_accuracy: 0.9816 - val_loss: 0.0632\n","Epoch 9/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 179ms/step - accuracy: 0.8713 - loss: 0.3892 - val_accuracy: 0.9741 - val_loss: 0.0730\n","Epoch 10/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.8805 - loss: 0.3518 - val_accuracy: 0.9854 - val_loss: 0.0471\n","Epoch 11/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 179ms/step - accuracy: 0.8818 - loss: 0.3539 - val_accuracy: 0.9812 - val_loss: 0.0592\n","Epoch 12/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 182ms/step - accuracy: 0.8864 - loss: 0.3271 - val_accuracy: 0.9875 - val_loss: 0.0408\n","Epoch 13/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 179ms/step - accuracy: 0.8819 - loss: 0.3642 - val_accuracy: 0.9837 - val_loss: 0.0520\n","Epoch 14/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 178ms/step - accuracy: 0.8887 - loss: 0.3204 - val_accuracy: 0.9816 - val_loss: 0.0489\n","Epoch 15/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 179ms/step - accuracy: 0.8845 - loss: 0.3340 - val_accuracy: 0.9753 - val_loss: 0.0707\n","Epoch 16/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 179ms/step - accuracy: 0.8923 - loss: 0.3242 - val_accuracy: 0.9862 - val_loss: 0.0386\n","Epoch 17/30\n","\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 178ms/step - accuracy: 0.9001 - loss: 0.2956 - val_accuracy: 0.9833 - val_loss: 0.0440\n"]}],"source":["# -------------------- #\n","# Fine-tune\n","# -------------------- #\n","\n","fine_tune_history = model.fit(\n","    train_dataset,\n","    batch_size=16, # Smaller batch size for fine-tuning\n","    validation_data=val_dataset,\n","    epochs=30,\n","    callbacks=[fine_tune_early_stopping, fine_tune_checkpoint],\n","    class_weight=class_weights\n",").history"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[]},"kernelspec":{"display_name":".kerasVenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"}},"nbformat":4,"nbformat_minor":0}
